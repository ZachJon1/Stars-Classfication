#Loading libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(moments)
library(e1071)
library(caret)
library(kableExtra)
library(corrplot)
library(knitr)
library(lattice)
library(psych)
library(car)
library(kernlab)
library(caret)
library(doParallel)
cl <- makePSOCKcluster(10)
registerDoParallel(cl)
#Loading dataset
df <- read.csv("star_classification.csv")
#df
nrow(df)
#check for missing data
sum(is.na(df))
#creating predictor df and response df and dropping unwanted predictors
predictors<-df%>%select(c(-obj_ID, -class, -rerun_ID,-run_ID, -cam_col,-field_ID, -spec_obj_ID, -fiber_ID, -MJD, -plate))
response<-df%>%select(c(class))
#predictors
#response
filteredPredictors<-df%>%select(c(-obj_ID, -class, -rerun_ID,-run_ID, -cam_col,-field_ID, -spec_obj_ID, -fiber_ID, -MJD, -plate))
#checking correlation
correlations = cor(predictors)
corrplot(correlations, order = "hclust", method = "number", type = "lower")
highCorr <- findCorrelation(correlations, cutoff = .95)
length(highCorr)
##filteredPredictors <- predictors[, -highCorr]
#dim(predictors)
#dim(filteredPredictors)
##filteredCorrelations = cor(filteredPredictors)
##corrplot(filteredCorrelations, order = "hclust")
#plotting histograms to see distribution
filteredPredictors %>%
gather() %>%
ggplot(aes(x = value))+
geom_histogram() +
facet_wrap(~ key, scales = "free") +
labs(x = NULL, y = NULL) +
theme_bw() +
theme(axis.ticks.y=element_blank())
#checking skewness values
skewValues <- apply(filteredPredictors, 2, skewness)
#skewValues
#determining bad data
#describe(filteredPredictors$u)
#describe(filteredPredictors$g)
#describe(filteredPredictors$z)
#filteredPredictors[which(filteredPredictors$u <0), ]
#filteredPredictors[which(filteredPredictors$g <0), ]
#filteredPredictors[which(filteredPredictors$z <0), ]
#dropping bad observation
filteredPredictors<-filteredPredictors%>%slice(-c(79544))
response<-response%>%slice(-c(79544))
#checking skewness values
skewValues <- apply(filteredPredictors, 2, skewness)
#skewValues
#pre-processing transformations
trans <- preProcess(filteredPredictors, method = c("BoxCox"))
#trans
# Apply the transformation:
transformedPred<- predict(trans, filteredPredictors)
#transformedPred
#checking skewness after transformation
skewValues <- apply(transformedPred, 2, skewness)
#skewValues
#plotting histograms to see distribution
transformedPred %>%
gather() %>%
ggplot(aes(x = value))+
geom_histogram() +
facet_wrap(~ key, scales = "free") +
labs(x = NULL, y = NULL) +
theme_bw() +
theme(axis.ticks.y=element_blank())
#checking for outliers via box plots
transformedPred %>%
gather() %>%
ggplot(aes(x ="", y = value))+
geom_boxplot(outlier.colour = "lightblue", fill="yellow") +
facet_wrap(~ key, scales = "free") +
labs(x = NULL, y = NULL) +
theme_bw() +
theme(axis.ticks.y=element_blank())
#removing outliers by SpatialSign
#pre-processing transformations
trans <- preProcess(transformedPred, method = c("spatialSign"))
#trans
# Apply the transformation:
transformedPred<- predict(trans, transformedPred)
#transformedPred
#checking for outliers after transformation
transformedPred %>%
gather() %>%
ggplot(aes(x ="", y = value))+
geom_boxplot(outlier.colour = "lightblue", fill="yellow") +
facet_wrap(~ key, scales = "free") +
labs(x = NULL, y = NULL) +
theme_bw() +
theme(axis.ticks.y=element_blank())
###############################################
#checking distribution of classes to decide on splitting method
barplot(table(response$class))
set.seed(980)
#stratifed random sampling
trainingRows <- createDataPartition(response$class, p = .70, list= FALSE)
nrow(trainingRows)
#creating training and testing data
trainPredictors <- transformedPred [trainingRows, ]
trainClasses <- response[trainingRows]
str(trainClasses)
# Do the same for the test set using negative integers.
testPredictors <- transformedPred[-trainingRows, ]
testClasses <- response[-trainingRows]
str(trainPredictors)
str(testPredictors)
str(trainClasses)
str(testClasses)
nrow(trainPredictors)
nrow(testPredictors)
#summary of data
summary(trainPredictors)
sum(is.na(trainPredictors))
#checking frequency distribution of training and test classes
barplot(table(response$class))
barplot(table(trainClasses))
barplot(table(testClasses))
#9. Support Vector Machines
svmGrid<- expand.grid(.sigma =c(1, 2),
.C = 2^(seq(-4, 6)))
set.seed(980)
ctrl <- trainControl(method = "cv", number = 10, summaryFunction = defaultSummary)
set.seed(980)
svmFit <- train(x=trainPredictors,
y =as.factor(trainClasses),
method = "svmRadial",
tuneGrid = svmGrid,
preProc = c("center", "scale"),
metric = "Kappa",
trControl = ctrl)
svmFit
plot(svmFit)
predictedSVM<-  predict(svmFit, testPredictors)
confusionMatrix(data = predictedSVM,
reference = as.factor(testClasses))
#9. Support Vector Machines
sigmaRangeReduced <- sigest(as.matrix(trainPredictors[,1:8]))
svmGrid<- expand.grid(.sigma = sigmaRangeReduced[1],
.C = 2^(seq(8, 20)))
set.seed(980)
ctrl <- trainControl(method = "cv", number = 10, summaryFunction = defaultSummary)
set.seed(980)
svmFit2 <- train(x=trainPredictors,
y =as.factor(trainClasses),
method = "svmRadial",
tuneGrid = svmGrid,
preProc = c("center", "scale"),
metric = "Kappa",
trControl = ctrl)
